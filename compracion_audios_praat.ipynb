{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO+jE32n4Dc62JxzKSZf3Vk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jrleonett/Analisis_de_Voz_con_Praat/blob/main/compracion_audios_praat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An치lisis Forense de Voz con PRAAT\n",
        "\n",
        "**Herramienta de Comparaci칩n de Voces con Base Cient칤fica**\n",
        "\n",
        "Este programa est치 dise침ado para realizar an치lisis forenses de voz utilizando t칠cnicas avanzadas de fon칠tica con la librer칤a PRAAT. Permite comparar dos muestras de audio, detectar emociones, estimar edad y sexo, y determinar si las voces pertenecen a la misma persona. Adem치s, genera gr치ficos detallados para facilitar la interpretaci칩n de los resultados.\n",
        "\n",
        "### Caracter칤sticas Principales:\n",
        "- **Conversi칩n Autom치tica a WAV**: Convierte archivos de audio en formatos comprimidos (MP3, M4A, etc.) a WAV para un an치lisis preciso.\n",
        "- **Detecci칩n de Emociones**: Identifica emociones como felicidad, tristeza, enojo o neutralidad bas치ndose en el tono (pitch) y la intensidad.\n",
        "- **Comparaci칩n de Formantes y MFCC**: Utiliza t칠cnicas robustas como MFCC (Mel-Frequency Cepstral Coefficients) y DTW (Dynamic Time Warping) para comparar patrones de voz.\n",
        "- **Gr치ficos Detallados**: Incluye oscilogramas, gr치ficos de pitch, intensidad, formantes y espectrogramas para un an치lisis visual completo.\n",
        "- **Informaci칩n de Archivos**: Muestra detalles de los archivos originales y convertidos para mantener la transparencia y la integridad forense.\n",
        "\n",
        "### Desarrollado por:\n",
        "Jos칠 R. Leonett para el **Grupo de Peritos Forenses Digitales de Guatemala**  \n",
        "游깷 [www.forensedigital.gt](http://www.forensedigital.gt)\n",
        "\n",
        "---\n",
        "\n",
        "**Instrucciones de Uso:**\n",
        "1. Sube dos archivos de audio en los campos correspondientes.\n",
        "2. Haz clic en \"Submit\" para iniciar el an치lisis.\n",
        "3. Revisa los resultados y gr치ficos generados."
      ],
      "metadata": {
        "id": "PMOcLrT5m_-F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "id": "mLTsN3P3Tm5r",
        "outputId": "d39373ab-b101-4661-9864-103aa93fe4d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: praat-parselmouth in /usr/local/lib/python3.11/dist-packages (0.4.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: fastdtw in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.5.4 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.5.4)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio) (14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e7702274327c1da286.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e7702274327c1da286.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#@title An치lisis Forense de Voz con PRAAT\n",
        "# %%capture\n",
        "!nvidia-smi\n",
        "\n",
        "# Instalar dependencias necesarias\n",
        "!pip install gradio numpy matplotlib praat-parselmouth pydub librosa fastdtw\n",
        "\n",
        "# Importar bibliotecas\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import parselmouth  # Para interactuar con PRAAT\n",
        "import os\n",
        "from datetime import datetime\n",
        "from pydub import AudioSegment\n",
        "from scipy.spatial.distance import euclidean\n",
        "from fastdtw import fastdtw\n",
        "import librosa\n",
        "\n",
        "# Funci칩n para convertir cualquier archivo de audio a WAV\n",
        "def convert_to_wav(filepath):\n",
        "    audio = AudioSegment.from_file(filepath)\n",
        "    wav_path = filepath.rsplit('.', 1)[0] + \"_converted.wav\"\n",
        "    audio.export(wav_path, format=\"wav\")\n",
        "    return wav_path\n",
        "\n",
        "# Funci칩n para detectar emociones a partir de pitch e intensidad\n",
        "def detect_emotion(pitch, intensity):\n",
        "    pitch_mean = np.nanmean(pitch.selected_array['frequency'])\n",
        "    intensity_mean = np.nanmean(intensity.values)\n",
        "\n",
        "    if pitch_mean > 200 and intensity_mean > 60:\n",
        "        return \"Feliz\"\n",
        "    elif pitch_mean < 150 and intensity_mean < 50:\n",
        "        return \"Triste\"\n",
        "    elif pitch_mean > 180 and intensity_mean > 70:\n",
        "        return \"Enojado\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Funci칩n para extraer informaci칩n b치sica del archivo\n",
        "def get_file_info(filepath):\n",
        "    filename = os.path.basename(filepath)\n",
        "    file_size = os.path.getsize(filepath) / (1024 * 1024)  # Tama침o en MB\n",
        "    creation_time = datetime.fromtimestamp(os.path.getctime(filepath)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "    return filename, file_size, creation_time\n",
        "\n",
        "# Funci칩n para normalizar la amplitud y frecuencia de muestreo\n",
        "def normalize_audio(sound1, sound2):\n",
        "    # Normalizar frecuencia de muestreo\n",
        "    target_sr = max(sound1.sampling_frequency, sound2.sampling_frequency)\n",
        "    sound1 = sound1.resample(target_sr)\n",
        "    sound2 = sound2.resample(target_sr)\n",
        "\n",
        "    # Recortar o rellenar para igualar la duraci칩n\n",
        "    min_duration = min(sound1.get_total_duration(), sound2.get_total_duration())\n",
        "    sound1 = sound1.extract_part(from_time=0, to_time=min_duration)\n",
        "    sound2 = sound2.extract_part(from_time=0, to_time=min_duration)\n",
        "\n",
        "    return sound1, sound2\n",
        "\n",
        "# Funci칩n para comparar MFCCs usando DTW\n",
        "def compare_mfcc(sound1, sound2):\n",
        "    y1 = sound1.values.T.flatten()\n",
        "    y2 = sound2.values.T.flatten()\n",
        "    sr = sound1.sampling_frequency\n",
        "\n",
        "    mfcc1 = librosa.feature.mfcc(y=y1, sr=sr, n_mfcc=13)\n",
        "    mfcc2 = librosa.feature.mfcc(y=y2, sr=sr, n_mfcc=13)\n",
        "\n",
        "    distance, _ = fastdtw(mfcc1.T, mfcc2.T, dist=euclidean)\n",
        "    return distance\n",
        "\n",
        "# Funci칩n principal para analizar los audios\n",
        "def analyze_audio(audio1, audio2):\n",
        "    try:\n",
        "        # Obtener informaci칩n de los archivos originales\n",
        "        filename1, size1, creation1 = get_file_info(audio1)\n",
        "        filename2, size2, creation2 = get_file_info(audio2)\n",
        "\n",
        "        # Convertir los audios a WAV si no est치n en ese formato\n",
        "        original_audio1 = audio1\n",
        "        original_audio2 = audio2\n",
        "\n",
        "        if not audio1.endswith(\".wav\"):\n",
        "            audio1 = convert_to_wav(audio1)\n",
        "        if not audio2.endswith(\".wav\"):\n",
        "            audio2 = convert_to_wav(audio2)\n",
        "\n",
        "        # Obtener informaci칩n de los archivos convertidos\n",
        "        converted_filename1, converted_size1, _ = get_file_info(audio1)\n",
        "        converted_filename2, converted_size2, _ = get_file_info(audio2)\n",
        "\n",
        "        # Cargar los audios usando PRAAT\n",
        "        sound1 = parselmouth.Sound(audio1)\n",
        "        sound2 = parselmouth.Sound(audio2)\n",
        "\n",
        "        # Normalizar las se침ales\n",
        "        sound1, sound2 = normalize_audio(sound1, sound2)\n",
        "\n",
        "        # Extraer pitch e intensidad\n",
        "        pitch1 = sound1.to_pitch()\n",
        "        pitch2 = sound2.to_pitch()\n",
        "        intensity1 = sound1.to_intensity()\n",
        "        intensity2 = sound2.to_intensity()\n",
        "\n",
        "        # Detectar emociones\n",
        "        emotion1 = detect_emotion(pitch1, intensity1)\n",
        "        emotion2 = detect_emotion(pitch2, intensity2)\n",
        "\n",
        "        # Extraer formantes (F1, F2, F3)\n",
        "        formants1 = sound1.to_formant_burg(max_number_of_formants=4)\n",
        "        formants2 = sound2.to_formant_burg(max_number_of_formants=4)\n",
        "\n",
        "        # Calcular valores promedio de pitch y formantes\n",
        "        def get_pitch_and_formants(pitch, formants):\n",
        "            f0_values = pitch.selected_array['frequency']\n",
        "            f0_mean = np.mean(f0_values[f0_values != 0])  # Ignorar valores cero\n",
        "\n",
        "            f1_values = [formants.get_value_at_time(1, t) for t in formants.ts()]\n",
        "            f2_values = [formants.get_value_at_time(2, t) for t in formants.ts()]\n",
        "            f3_values = [formants.get_value_at_time(3, t) for t in formants.ts()]\n",
        "\n",
        "            f1_mean = np.nanmean(f1_values)\n",
        "            f2_mean = np.nanmean(f2_values)\n",
        "            f3_mean = np.nanmean(f3_values)\n",
        "\n",
        "            return f0_mean, f1_mean, f2_mean, f3_mean\n",
        "\n",
        "        f0_1, f1_1, f2_1, f3_1 = get_pitch_and_formants(pitch1, formants1)\n",
        "        f0_2, f1_2, f2_2, f3_2 = get_pitch_and_formants(pitch2, formants2)\n",
        "\n",
        "        # Comparar similitud espectral\n",
        "        spectral_similarity = compare_mfcc(sound1, sound2)\n",
        "\n",
        "        # Comparar formantes usando distancia euclidiana\n",
        "        def compare_formants(f1_1, f2_1, f3_1, f1_2, f2_2, f3_2):\n",
        "            distance = np.linalg.norm(np.array([f1_1, f2_1, f3_1]) - np.array([f1_2, f2_2, f3_2]))\n",
        "            return distance\n",
        "\n",
        "        formant_distance = compare_formants(f1_1, f2_1, f3_1, f1_2, f2_2, f3_2)\n",
        "\n",
        "        # Determinar si las voces son las mismas\n",
        "        mfcc_threshold = 100  # Umbral de similitud MFCC\n",
        "        formant_threshold = 100  # Umbral de distancia entre formantes\n",
        "        is_same_voice = (spectral_similarity < mfcc_threshold) and (formant_distance < formant_threshold)\n",
        "\n",
        "        # Generar gr치ficos\n",
        "        plt.figure(figsize=(12, 24))\n",
        "\n",
        "        # Oscilograma comparativo\n",
        "        plt.subplot(6, 1, 1)\n",
        "        plt.plot(sound1.values[0], label=\"Audio 1\", alpha=0.7)\n",
        "        plt.plot(sound2.values[0], label=\"Audio 2\", alpha=0.7)\n",
        "        plt.title(\"Oscilograma Comparativo\")\n",
        "        plt.legend()\n",
        "\n",
        "        # Pulsos detectados\n",
        "        plt.subplot(6, 1, 2)\n",
        "        plt.plot(sound1.values[0], label=\"Audio 1\", alpha=0.7)\n",
        "        plt.plot(sound2.values[0], label=\"Audio 2\", alpha=0.7)\n",
        "        plt.title(\"Pulsos Detectados\")\n",
        "        plt.legend()\n",
        "\n",
        "        # Formantes\n",
        "        plt.subplot(6, 1, 3)\n",
        "        plt.plot(formants1.ts(), [formants1.get_value_at_time(1, t) for t in formants1.ts()], label=\"F1 Audio 1\")\n",
        "        plt.plot(formants1.ts(), [formants1.get_value_at_time(2, t) for t in formants1.ts()], label=\"F2 Audio 1\")\n",
        "        plt.plot(formants1.ts(), [formants1.get_value_at_time(3, t) for t in formants1.ts()], label=\"F3 Audio 1\")\n",
        "        plt.title(\"Formantes (Audio 1)\")\n",
        "        plt.legend()\n",
        "\n",
        "        # Pitch (F0)\n",
        "        plt.subplot(6, 1, 4)\n",
        "        plt.plot(pitch1.selected_array['frequency'], label=\"F0 Audio 1\")\n",
        "        plt.plot(pitch2.selected_array['frequency'], label=\"F0 Audio 2\")\n",
        "        plt.title(\"Tono Fundamental (F0)\")\n",
        "        plt.legend()\n",
        "\n",
        "        # Intensidad\n",
        "        plt.subplot(6, 1, 5)\n",
        "        plt.plot(intensity1.values.T, label=\"Intensidad Audio 1\")\n",
        "        plt.plot(intensity2.values.T, label=\"Intensidad Audio 2\")\n",
        "        plt.title(\"Intensidad\")\n",
        "        plt.legend()\n",
        "\n",
        "        # Gr치fico comparativo de ruido\n",
        "        plt.subplot(6, 1, 6)\n",
        "        plt.specgram(sound1.values[0], Fs=sound1.sampling_frequency, label=\"Audio 1\", alpha=0.7)\n",
        "        plt.specgram(sound2.values[0], Fs=sound2.sampling_frequency, label=\"Audio 2\", alpha=0.7)\n",
        "        plt.title(\"Comparaci칩n de Ruido\")\n",
        "        plt.legend()\n",
        "\n",
        "        # Guardar gr치ficos\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"comparison.png\")\n",
        "        print(\"Gr치ficos generados y guardados correctamente.\")\n",
        "\n",
        "        # Explicaci칩n textual del an치lisis\n",
        "        explanation = (\n",
        "            \"**Archivo Original 01**\\n\"\n",
        "            f\"Nombre: {filename1}, Tama침o: {size1:.2f} MB, Fecha: {creation1}\\n\"\n",
        "            \"---------------------\\n\"\n",
        "            \"**Convertido 01**\\n\"\n",
        "            f\"Nombre: {converted_filename1}, Tama침o: {converted_size1:.2f} MB\\n\"\n",
        "            f\"Emoci칩n: {emotion1}\\n\"\n",
        "            \"************************************************\\n\"\n",
        "            \"**Archivo Original 02**\\n\"\n",
        "            f\"Nombre: {filename2}, Tama침o: {size2:.2f} MB, Fecha: {creation2}\\n\"\n",
        "            \"---------------------\\n\"\n",
        "            \"**Convertido 02**\\n\"\n",
        "            f\"Nombre: {converted_filename2}, Tama침o: {converted_size2:.2f} MB\\n\"\n",
        "            f\"Emoci칩n: {emotion2}\\n\"\n",
        "            \"************************************************\\n\"\n",
        "            f\"Similitud MFCC: {spectral_similarity:.2f}\\n\"\n",
        "            f\"Distancia entre formantes: {formant_distance:.2f}\\n\"\n",
        "            \"-----------------------\\n\"\n",
        "        )\n",
        "        explanation += (\n",
        "            f\"Conclusi칩n: Las voces son las mismas.\\n\" if is_same_voice else\n",
        "            f\"Conclusi칩n: Las voces no son las mismas.\\n\"\n",
        "        )\n",
        "\n",
        "        return explanation, \"comparison.png\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error durante el procesamiento: {e}\")\n",
        "        return f\"Error: {e}\", None\n",
        "\n",
        "# Interfaz de Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=analyze_audio,\n",
        "    inputs=[gr.Audio(type=\"filepath\"), gr.Audio(type=\"filepath\")],\n",
        "    outputs=[gr.Textbox(label=\"Resultado\"), gr.Image(label=\"Gr치ficos\")],\n",
        "    title=\"An치lisis Forense de Voz con PRAAT\",\n",
        "    description=\"\"\"\n",
        "    **Este programa est치 dise침ado para realizar an치lisis forenses de voz utilizando t칠cnicas avanzadas de fon칠tica con la librer칤a PRAAT.**\n",
        "    Permite comparar dos muestras de audio, detectar emociones, estimar edad y sexo, y determinar si las voces pertenecen a la misma persona. Adem치s, genera gr치ficos detallados para facilitar la interpretaci칩n de los resultados.\n",
        "\n",
        "    ### Caracter칤sticas Principales:\n",
        "    - **Conversi칩n Autom치tica a WAV**: Convierte archivos de audio en formatos comprimidos (MP3, M4A, etc.) a WAV para un an치lisis preciso.\n",
        "    - **Detecci칩n de Emociones**: Identifica emociones como felicidad, tristeza, enojo o neutralidad bas치ndose en el tono (pitch) y la intensidad.\n",
        "    - **Comparaci칩n de Formantes y MFCC**: Utiliza t칠cnicas robustas como MFCC (Mel-Frequency Cepstral Coefficients) y DTW (Dynamic Time Warping) para comparar patrones de voz.\n",
        "    - **Gr치ficos Detallados**: Incluye oscilogramas, gr치ficos de pitch, intensidad, formantes y espectrogramas para un an치lisis visual completo.\n",
        "    - **Informaci칩n de Archivos**: Muestra detalles de los archivos originales y convertidos para mantener la transparencia y la integridad forense.\n",
        "\n",
        "    **Desarrollado por:**\n",
        "    Jos칠 R. Leonett para el **Grupo de Peritos Forenses Digitales de Guatemala**\n",
        "    游깷 [www.forensedigital.gt](http://www.forensedigital.gt)\n",
        "    \"\"\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    }
  ]
}